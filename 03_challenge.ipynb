{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Challenge - Second DAG\n",
    "\n",
    "I used a method of hooks, python operators and XCom to make the given DAG work. In this document I will compare relevant sections of code to explain the changes I made, with the original code first and my code second. My full code is at the end and successfully produced a local postgres table with the summary information.\n",
    "\n",
    "### Connections\n",
    "\n",
    "The first thing I did was set up appropriate MySql and postgres connections on the airflow webserver to connect to the two databases, I made a new postgres database for this challenge.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "I imported a few extra tools to make the solution work; python operator, hooks for both mysql and postgres, and XCom. I didn't need the datetime, mysql/postgres operators so these were not imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recieved Code\n",
    "from datetime import datetime, timedelta\n",
    "from airflow import DAG\n",
    "from airflow.providers.mysql.operators.mysql import MySqlOperator\n",
    "from airflow.providers.postgres.operators.postgres import PostgresOperator\n",
    "\n",
    "# My Code\n",
    "from airflow import DAG\n",
    "from airflow.providers.mysql.hooks.mysql import  MySqlHook\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.models.xcom import XCom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default_args stayed the same except I changed the retry_delay to 2 minutes so that I could get results faster.\n",
    "\n",
    "The creation of a dag DAG object was reformatted but the parameters were unchanged.\n",
    "\n",
    "The main change to the code structure was the sql queries for each task becoming python functions with more complex operations, one of which was executing these sql queries. The tasks themselves were changed to Python Operators but the aim of each task was kept the same. Each operator calls a python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recieved Code\n",
    "\n",
    "t1 = PostgresOperator(\n",
    "    task_id='create_account_summary',\n",
    "    sql=create_account_summary,\n",
    "    postgres_conn_id='local_postgres',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "t2 = MySqlOperator(\n",
    "    task_id='extract_financial_data',\n",
    "    sql=extract_financial_data,\n",
    "    mysql_conn_id='financial_mariadb',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "t3 = PostgresOperator(\n",
    "    task_id='load_account_summary',\n",
    "    sql=load_account_summary,\n",
    "    postgres_conn_id='local_postgres',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "t1 >> t2 >> t3\n",
    "\n",
    "# My Code\n",
    "\n",
    "t1 = PythonOperator(\n",
    "    task_id='create_account_summary',\n",
    "    python_callable=_create_account_summary,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "t2 = PythonOperator(\n",
    "    task_id='extract_financial_data',\n",
    "    python_callable=_extract_financial_data,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "t3 = PythonOperator(\n",
    "    task_id='load_account_summary',\n",
    "    python_callable=_load_account_summary,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "t1 >> t2 >> t3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t1 - Create Account Summary\n",
    "\n",
    "The same SQL query was used with the addition of a line to drop the table if it already exsisted so I didn't have to manually delete the table each time I ran the DAG. \n",
    "\n",
    "The primary difference was in changing the Operator from postgres to python I had to add a hook to use the postgres connection I had set-up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recieved Code\n",
    "create_account_summary = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS account_summary (\n",
    "        account_id INT PRIMARY KEY,\n",
    "        total_transactions INT,\n",
    "        total_amount NUMERIC\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "# My Code\n",
    "def _create_account_summary():\n",
    "    request = \"DROP TABLE IF EXISTS account_summary; CREATE TABLE account_summary (account_id INT PRIMARY KEY,total_transactions INT,total_amount NUMERIC);\"\n",
    "    pg_hook = PostgresHook(postgres_conn_id='local_postgres', schema='batch_process_03')\n",
    "    connection = pg_hook.get_conn()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(request)\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t2 - Extract Financial Data\n",
    "\n",
    "Similarly to t1 the same basic SQL query was used to extract and manipulate the relevant data, in this case removing the attempt to send the data to a local csv file as my guest user did not have the ability to do this. I used a mysql hook this time to connect to the database rather than the MySql Operator.\n",
    "\n",
    "Once I had the data I had to push it to airflow using XCom so that it could be accessed in the next task. I used the airflow webserver to see the XComs and check that they were being pushed correctly. I considered turning the data into a panda dataframe but it was suggested online this was not good practice so I left the data in the tuple form it came out of the query in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recieved Code\n",
    "extract_financial_data = \"\"\"\n",
    "    SELECT account_id, COUNT(*) AS total_transactions, SUM(amount) AS total_amount\n",
    "    FROM trans\n",
    "    GROUP BY account_id\n",
    "    INTO OUTFILE '/tmp/account_summary.csv'\n",
    "    FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '\\\"'\n",
    "    LINES TERMINATED BY '\\n';\n",
    "\"\"\"\n",
    "\n",
    "# My Code\n",
    "def _extract_financial_data(ti):\n",
    "    request = \"SELECT account_id, COUNT(*) AS total_transactions, SUM(amount) AS total_amount FROM trans GROUP BY account_id;\"\n",
    "    ms_hook = MySqlHook(mysql_conn_id='financial_mariadb', schema='financial')\n",
    "    connection = ms_hook.get_conn()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(request)\n",
    "    data = cursor.fetchall()\n",
    "    ti.xcom_push(key='data', value = data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t3 - Load Account Summary\n",
    "\n",
    "This task XCom pulls the data so that it can be used in this task. Another postgres hook is used to allow the use of the postgres connection. The data is inserted line by line into the table created in t1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recieved Code\n",
    "load_account_summary = \"\"\"\n",
    "    COPY account_summary(account_id, total_transactions, total_amount)\n",
    "    FROM '/tmp/account_summary.csv' WITH CSV;\n",
    "\"\"\"\n",
    "# My Code\n",
    "def _load_account_summary(ti):\n",
    "    data = ti.xcom_pull(key='data', task_ids='extract_financial_data')\n",
    "    pg_hook = PostgresHook(postgres_conn_id='local_postgres', schema='batch_process_03')\n",
    "    connection = pg_hook.get_conn()\n",
    "    cursor = connection.cursor()\n",
    "    for row in data:\n",
    "        request = f\"INSERT INTO account_summary(account_id, total_transactions, total_amount) VALUES ({row[0]},{row[1]},{row[2]})\"\n",
    "        cursor.execute(request)\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My full code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.providers.mysql.hooks.mysql import  MySqlHook\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.models.xcom import XCom\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=2),\n",
    "}\n",
    "\n",
    "def _create_account_summary():\n",
    "    request = \"DROP TABLE IF EXISTS account_summary; CREATE TABLE account_summary (account_id INT PRIMARY KEY,total_transactions INT,total_amount NUMERIC);\"\n",
    "    pg_hook = PostgresHook(postgres_conn_id='local_postgres', schema='batch_process_03')\n",
    "    connection = pg_hook.get_conn()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(request)\n",
    "    connection.commit()\n",
    "\n",
    "def _extract_financial_data(ti):\n",
    "    request = \"SELECT account_id, COUNT(*) AS total_transactions, SUM(amount) AS total_amount FROM trans GROUP BY account_id;\"\n",
    "    ms_hook = MySqlHook(mysql_conn_id='financial_mariadb', schema='financial')\n",
    "    connection = ms_hook.get_conn()\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(request)\n",
    "    data = cursor.fetchall()\n",
    "    ti.xcom_push(key='data', value = data)\n",
    "\n",
    "def _load_account_summary(ti):\n",
    "    data = ti.xcom_pull(key='data', task_ids='extract_financial_data')\n",
    "    pg_hook = PostgresHook(postgres_conn_id='local_postgres', schema='batch_process_03')\n",
    "    connection = pg_hook.get_conn()\n",
    "    cursor = connection.cursor()\n",
    "    for row in data:\n",
    "        request = f\"INSERT INTO account_summary(account_id, total_transactions, total_amount) VALUES ({row[0]},{row[1]},{row[2]})\"\n",
    "        cursor.execute(request)\n",
    "    connection.commit()\n",
    "\n",
    "with DAG(\n",
    "    'financial_dag',\n",
    "    default_args=default_args,\n",
    "    description='A financial data extraction and loading DAG',\n",
    "    schedule_interval=timedelta(days=1),\n",
    "    start_date=datetime(2023, 4, 28),\n",
    "    catchup=False,\n",
    ")as dag:\n",
    "    \n",
    "    t1 = PythonOperator(\n",
    "        task_id='create_account_summary',\n",
    "        python_callable=_create_account_summary,\n",
    "        dag=dag,\n",
    "    )\n",
    "\n",
    "    t2 = PythonOperator(\n",
    "        task_id='extract_financial_data',\n",
    "        python_callable=_extract_financial_data,\n",
    "        dag=dag,\n",
    "    )\n",
    "\n",
    "    t3 = PythonOperator(\n",
    "        task_id='load_account_summary',\n",
    "        python_callable=_load_account_summary,\n",
    "        dag=dag,\n",
    "    )\n",
    "\n",
    "t1 >> t2 >> t3\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
